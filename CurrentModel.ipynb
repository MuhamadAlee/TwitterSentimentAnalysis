{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tweepy \n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re \n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.regularizers import l1_l2, l2, l1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#twitter Account Keys\n",
    "consumerKey = \"L7o3Yf6HD1o55Q9qcJuuoYcuC\"\n",
    "consumerSecret = \"s3kZeTFtd6DO5Jvkw6MkFfOwye38TqnksNEEk8uakZujVNFC2D\"\n",
    "accessToken = \"3235982888-D8VdbzDEUmtLaQvBjMazprLLOJpr0U6I3ZKhGwl\"\n",
    "accessTokenSecret = \"RvXhR9hLRS0C9dyHEu2VvMJdRG6qIavATJRSxZP1Hpm8x\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the authentication object\n",
    "authenticate = tweepy.OAuthHandler(consumerKey, consumerSecret) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the access token and access token secret\n",
    "authenticate.set_access_token(accessToken, accessTokenSecret) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the API object while passing in auth information\n",
    "api = tweepy.API(authenticate, wait_on_rate_limit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg = api.user_timeline(screen_name=\"BillGates\", count = 200, lang =\"en\", tweet_mode=\"extended\")\n",
    "bo = api.user_timeline(screen_name=\"BarackObama\", count = 200, lang =\"en\", tweet_mode=\"extended\")\n",
    "hc = api.user_timeline(screen_name=\"HillaryClinton\", count = 200, lang =\"en\", tweet_mode=\"extended\")\n",
    "bj= api.user_timeline(screen_name=\"BorisJohnson\", count = 200, lang =\"en\", tweet_mode=\"extended\")\n",
    "bc = api.user_timeline(screen_name=\"jeremycorbyn\", count = 200, lang =\"en\", tweet_mode=\"extended\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alee\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# Create a dataframe with a column called Tweets\n",
    "df1 = pd.DataFrame([tweet.full_text for tweet in bo], columns=['Tweets'])\n",
    "\n",
    "\n",
    "df1['Writer'] = 'BarackObama'\n",
    "\n",
    "df2 =pd.DataFrame([tweet.full_text for tweet in bg], columns=['Tweets'])\n",
    "\n",
    "df2['Writer'] = 'BillGates'\n",
    "\n",
    "df3 = pd.DataFrame([tweet.full_text for tweet in hc], columns=['Tweets'])\n",
    "\n",
    "df3['Writer'] = 'HillaryClinton'\n",
    "\n",
    "df4 = pd.DataFrame([tweet.full_text for tweet in bj], columns=['Tweets'])\n",
    "\n",
    "df4['Writer'] = 'BorisJohnson'\n",
    "\n",
    "df5 = pd.DataFrame([tweet.full_text for tweet in bc], columns=['Tweets'])\n",
    "\n",
    "df5['Writer'] = 'JeremyCorbyn'\n",
    "\n",
    "data = pd.read_csv('Dataset\\Random.csv', encoding='latin-1', usecols=['SentimentText'])\n",
    "data=data.astype(str)\n",
    "d6=data.head(200)\n",
    "d6['Writer'] = 'Random'\n",
    "d6.columns=['Tweets','Writer']\n",
    "\n",
    "df = pd.concat([df1, df2, df3, df4, df5,d6])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to clean the tweets\n",
    "import re\n",
    "def cleanTxt(text):\n",
    " text = re.sub('@[A-Za-z0–9]+', '', text) #Removing @mentions\n",
    " text = re.sub('#', '', text) # Removing '#' hash tag\n",
    " \n",
    " text = re.sub('RT[\\s]+', '', text) # Removing RT\n",
    " text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    " text = re.sub('https?:\\/\\/\\S+', '', text) # Removing hyperlink\n",
    " text=text.lower() #converting to lowercase\n",
    " text = re.sub(':', '', text) # Removing  \n",
    " return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the tweets\n",
    "df['Tweets'] = df['Tweets'].apply(cleanTxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Writer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i will never forget the commitment to reconcil...</td>\n",
       "      <td>BarackObama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>we have to treat voting as the most important ...</td>\n",
       "      <td>BarackObama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>let’s guarantee that every citizen has equal r...</td>\n",
       "      <td>BarackObama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>we can do this by making sure every american i...</td>\n",
       "      <td>BarackObama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>we've got to fight harder to protect the right...</td>\n",
       "      <td>BarackObama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>17  told you, you would sweep haha -p</td>\n",
       "      <td>Random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>. there r many gr8 science cartoons</td>\n",
       "      <td>Random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>- 1 edinburgh fringe is only 10 weeks away?! i...</td>\n",
       "      <td>Random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>why didnt you come to school?? have you done...</td>\n",
       "      <td>Random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>-  which one?   or  - latter for the us store ...</td>\n",
       "      <td>Random</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Tweets       Writer\n",
       "0    i will never forget the commitment to reconcil...  BarackObama\n",
       "1    we have to treat voting as the most important ...  BarackObama\n",
       "2    let’s guarantee that every citizen has equal r...  BarackObama\n",
       "3    we can do this by making sure every american i...  BarackObama\n",
       "4    we've got to fight harder to protect the right...  BarackObama\n",
       "..                                                 ...          ...\n",
       "195              17  told you, you would sweep haha -p       Random\n",
       "196            . there r many gr8 science cartoons           Random\n",
       "197  - 1 edinburgh fringe is only 10 weeks away?! i...       Random\n",
       "198    why didnt you come to school?? have you done...       Random\n",
       "199  -  which one?   or  - latter for the us store ...       Random\n",
       "\n",
       "[1200 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the new dataframe with columns 'Subjectivity' & 'Polarity'\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('Dataset/NewTweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Dataset/NewTweets.csv')\n",
    "\n",
    "df.to_pickle(\"Dataset/NewTweets.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Create feature vectors\n",
    "vectorizer = TfidfVectorizer(min_df = 5,\n",
    "                             max_df = 0.8,\n",
    "                             sublinear_tf = True,\n",
    "                             use_idf = True)\n",
    "train_vectors = vectorizer.fit_transform(df['Tweets'])\n",
    "test_vectors = vectorizer.transform(df['Tweets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.347676s; Prediction time: 0.247769s\n",
      "BarackObama:  {'precision': 0.9182692307692307, 'recall': 0.955, 'f1-score': 0.9362745098039216, 'support': 200}\n",
      "BillGates:  {'precision': 0.9552238805970149, 'recall': 0.96, 'f1-score': 0.9576059850374063, 'support': 200}\n",
      "HillaryClinton:  {'precision': 0.9368421052631579, 'recall': 0.89, 'f1-score': 0.9128205128205129, 'support': 200}\n",
      "BorisJohnson:  {'precision': 0.9651741293532339, 'recall': 0.97, 'f1-score': 0.9675810473815462, 'support': 200}\n",
      "JeremyCorbyn:  {'precision': 0.9790575916230366, 'recall': 0.935, 'f1-score': 0.9565217391304348, 'support': 200}\n",
      "Random:  {'precision': 0.9090909090909091, 'recall': 0.95, 'f1-score': 0.9290953545232273, 'support': 200}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "# Perform classification with SVM, kernel=linear\n",
    "classifier_linear = svm.SVC(kernel='linear')\n",
    "t0 = time.time()\n",
    "classifier_linear.fit(train_vectors, df['Writer'])\n",
    "t1 = time.time()\n",
    "prediction_linear = classifier_linear.predict(test_vectors)\n",
    "t2 = time.time()\n",
    "time_linear_train = t1-t0\n",
    "time_linear_predict = t2-t1\n",
    "# results\n",
    "print(\"Training time: %fs; Prediction time: %fs\" % (time_linear_train, time_linear_predict))\n",
    "report = classification_report(df['Writer'], prediction_linear, output_dict=True)\n",
    "\n",
    "print('BarackObama: ', report['BarackObama'])\n",
    "print('BillGates: ', report['BillGates'])\n",
    "print('HillaryClinton: ', report['HillaryClinton'])\n",
    "print('BorisJohnson: ', report['BorisJohnson'])\n",
    "print('JeremyCorbyn: ', report['JeremyCorbyn'])\n",
    "print('Random: ', report['Random'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BarackObama']\n"
     ]
    }
   ],
   "source": [
    "review = \"On Memorial Day, we honor those who gave all for us. That takes different forms this year, but it’s even more vital with the loss of so many veterans to COVID-19.The way they lived, in service to one another, should be our roadmap in the months ahead.\"\n",
    "review_vector = vectorizer.transform([review]) # vectorizing\n",
    "print(classifier_linear.predict(review_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# pickling the vectorizer\n",
    "pickle.dump(vectorizer, open('Data/vect.sav', 'wb'))\n",
    "# pickling the model\n",
    "pickle.dump(classifier_linear, open('Data/clas.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "vectorizer = pickle.load(open(\"Data/vect.sav\", \"rb\"))\n",
    "classifier_linear= pickle.load(open(\"Data/clas.sav\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BillGates\n"
     ]
    }
   ],
   "source": [
    "review = \"Class of 2020, these are not easy times. But we will get through them. And with your leadership, the world will be stronger than before.\" # vectorizing\n",
    "review_vector = vectorizer.transform([review])\n",
    "print(classifier_linear.predict(review_vector)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
